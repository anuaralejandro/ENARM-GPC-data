#!/usr/bin/env python3
"""
Clasificaci√≥n sem√°ntica de GPCs usando embeddings + similitud coseno
Optimizado para GPU y t√©rminos m√©dicos en espa√±ol
"""

import json
import torch
import numpy as np
from sentence_transformers import SentenceTransformer
from pathlib import Path
from tqdm import tqdm
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n
DATA_DIR = Path(__file__).parent.parent / "data"
DOCS_DIR = Path(__file__).parent.parent / "docs"
GOD_MODE_FILE = DATA_DIR / "gpc_links_god_mode.json"
OUTPUT_FILE = DOCS_DIR / "gpc_links_god_mode_classified.md"

# Taxonom√≠a m√©dica detallada
ESPECIALIDADES = {
    "Cirug√≠a General": [
        "apendicitis", "hernias", "colecistitis", "abscesos", "laparotom√≠a", "laparoscopia",
        "obstrucci√≥n intestinal", "hemorragia digestiva", "peritonitis", "cirug√≠a",
        "abdomen agudo", "trauma abdominal", "infecci√≥n sitio quir√∫rgico", "quemaduras"
    ],
    "Medicina Interna": [
        "diabetes", "hipertensi√≥n", "dislipidemia", "obesidad", "s√≠ndrome metab√≥lico",
        "insuficiencia renal", "enfermedad renal", "anemia", "hepatitis", "cirrosis",
        "tuberculosis", "VIH", "SIDA", "neumon√≠a", "EPOC", "asma", "enfermedad pulmonar",
        "trombosis", "embolia", "anticoagulaci√≥n", "hipertiroidismo", "hipotiroidismo"
    ],
    "Pediatr√≠a": [
        "neonatal", "lactante", "ni√±o", "pedi√°trica", "pedi√°trico", "reci√©n nacido",
        "prematuridad", "bajo peso al nacer", "ictericia neonatal", "hiperbilirrubinemia",
        "diarrea aguda", "deshidrataci√≥n", "desnutrici√≥n", "vacunaci√≥n", "desarrollo infantil"
    ],
    "Ginecolog√≠a y Obstetricia": [
        "embarazo", "gestaci√≥n", "parto", "ces√°rea", "preeclampsia", "eclampsia",
        "amenaza de aborto", "aborto", "hemorragia obst√©trica", "puerperio",
        "control prenatal", "cervicouterino", "mama", "mamario", "ovario", "√∫tero",
        "menstruaci√≥n", "menopausia", "anticoncepci√≥n", "planificaci√≥n familiar"
    ],
    "Traumatolog√≠a y Ortopedia": [
        "fractura", "luxaci√≥n", "esguince", "trauma", "ortop√©dica", "ortop√©dico",
        "columna", "rodilla", "cadera", "hombro", "mano", "pie", "hueso",
        "articulaci√≥n", "ligamento", "menisco", "pr√≥tesis", "osteomielitis"
    ],
    "Cardiolog√≠a": [
        "cardio", "coraz√≥n", "infarto", "miocardio", "angina", "arritmia",
        "insuficiencia cardiaca", "valvular", "v√°lvula", "endocarditis",
        "pericarditis", "hipertensi√≥n arterial", "coronaria", "stent"
    ],
    "Neurolog√≠a": [
        "cerebro", "cerebral", "neurol√≥g", "epilepsia", "convulsiones", "crisis convulsiva",
        "ictus", "evento vascular cerebral", "EVC", "cefalea", "migra√±a", "Parkinson",
        "Alzheimer", "demencia", "neuropat√≠a", "esclerosis", "meningitis", "encefalitis"
    ],
    "Oftalmolog√≠a": [
        "ojo", "ocular", "oft√°lm", "retina", "catarata", "glaucoma", "conjuntivitis",
        "blefaritis", "queratitis", "uve√≠tis", "degeneraci√≥n macular", "retinopat√≠a",
        "agudeza visual", "visi√≥n", "estrabismo"
    ],
    "Otorrinolaringolog√≠a": [
        "o√≠do", "nariz", "garganta", "otitis", "rinosinusitis", "sinusitis", "faringitis",
        "amigdalitis", "laringitis", "v√©rtigo", "mareo", "sordera", "hipoacusia",
        "epistaxis", "rinitis", "olfato", "audici√≥n", "ORL"
    ],
    "Urolog√≠a": [
        "ri√±√≥n", "vejiga", "pr√≥stata", "uretra", "ur√©ter", "urolog√≠a", "urol√≥gico",
        "c√°lculo renal", "litiasis", "infecci√≥n urinaria", "IVU", "incontinencia urinaria",
        "hiperplasia prost√°tica", "c√°ncer pr√≥stata", "pene", "test√≠culo", "escroto"
    ],
    "Dermatolog√≠a": [
        "piel", "dermatitis", "psoriasis", "acn√©", "eccema", "√∫lcera", "lesi√≥n cut√°nea",
        "melanoma", "carcinoma", "infecci√≥n piel", "celulitis", "erisipela",
        "herpes", "varicela", "micosis", "hongos", "alopecia"
    ],
    "Psiquiatr√≠a": [
        "depresi√≥n", "ansiedad", "psicosis", "esquizofrenia", "bipolar", "psiqui√°tric",
        "salud mental", "suicidio", "adicci√≥n", "dependencia", "alcohol", "drogas",
        "trastorno mental", "demencia", "d√©ficit atenci√≥n", "TDAH", "autismo"
    ],
    "Medicina de Urgencias": [
        "urgencia", "emergencia", "trauma", "politraumatizado", "choque", "shock",
        "reanimaci√≥n", "RCP", "ATLS", "paro cardiaco", "intoxicaci√≥n", "envenenamiento",
        "mordedura", "picadura", "quemadura", "electrocuci√≥n", "ahogamiento"
    ],
    "Anestesiolog√≠a": [
        "anestesia", "anest√©sico", "sedaci√≥n", "analgesia", "dolor agudo", "dolor cr√≥nico",
        "bloqueo", "espinal", "epidural", "intubaci√≥n", "v√≠a a√©rea", "ventilaci√≥n"
    ],
    "Oncolog√≠a": [
        "c√°ncer", "tumor", "neoplasia", "maligno", "met√°stasis", "quimioterapia",
        "radioterapia", "oncol√≥gic", "carcinoma", "sarcoma", "leucemia", "linfoma"
    ]
}

def mean_pooling(model_output, attention_mask):
    """Mean pooling para obtener sentence embeddings"""
    token_embeddings = model_output[0]
    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)

def get_embedding(text: str, model):
    """Obtener embedding de un texto usando SentenceTransformer"""
    return model.encode(text, convert_to_tensor=True, normalize_embeddings=True)

def classify_gpc_semantic(title: str, especialidad_embeddings, model):
    """
    Clasificar GPC usando similitud coseno con embeddings de especialidades
    """
    # Obtener embedding del t√≠tulo
    title_embedding = get_embedding(title.lower(), model)
    
    # Calcular similitud con cada especialidad
    best_specialty = None
    best_score = -1
    
    for especialidad, emb in especialidad_embeddings.items():
        # Similitud coseno (embeddings ya normalizados)
        similarity = torch.dot(title_embedding, emb).item()
        
        if similarity > best_score:
            best_score = similarity
            best_specialty = especialidad
    
    # Convertir similitud coseno ([-1, 1]) a porcentaje de confianza
    confidence = ((best_score + 1) / 2) * 100  # Normalizar a [0, 100]
    
    return {
        "especialidad": best_specialty,
        "confianza": round(confidence, 1),
        "score_raw": round(best_score, 3)
    }

def create_especialidad_embeddings(model):
    """
    Crear embeddings representativos para cada especialidad
    basados en las palabras clave
    """
    print("üîß Creando embeddings de especialidades...")
    especialidad_embeddings = {}
    
    for especialidad, keywords in ESPECIALIDADES.items():
        # Crear texto representativo de la especialidad
        representative_text = " ".join(keywords)
        
        # Obtener embedding
        embedding = get_embedding(representative_text, model)
        especialidad_embeddings[especialidad] = embedding
        
        print(f"   ‚úÖ {especialidad}: {len(keywords)} t√©rminos clave")
    
    print()
    return especialidad_embeddings

def generate_markdown(classified_gpcs: list, output_file: Path):
    """
    Generar markdown organizado jer√°rquicamente
    """
    print("üìù Generando documento markdown...")
    
    # Agrupar por especialidad
    by_specialty = {}
    for gpc in classified_gpcs:
        specialty = gpc['classification']['especialidad']
        if specialty not in by_specialty:
            by_specialty[specialty] = []
        by_specialty[specialty].append(gpc)
    
    # Ordenar especialidades por n√∫mero de GPCs
    sorted_specialties = sorted(by_specialty.items(), key=lambda x: len(x[1]), reverse=True)
    
    # Generar contenido
    lines = [
        "# üìö Gu√≠as de Pr√°ctica Cl√≠nica - Clasificadas por Especialidad",
        "",
        f"**Total de GPCs:** {len(classified_gpcs)}",
        f"**Fecha de generaci√≥n:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "## üìä Resumen por Especialidad",
        "",
        "| Especialidad | Cantidad | % Total |",
        "|--------------|----------|---------|"
    ]
    
    for specialty, gpcs in sorted_specialties:
        percentage = (len(gpcs) / len(classified_gpcs)) * 100
        lines.append(f"| {specialty} | {len(gpcs)} | {percentage:.1f}% |")
    
    lines.extend(["", "---", ""])
    
    # Detalles por especialidad
    for specialty, gpcs in sorted_specialties:
        lines.append(f"## {specialty} ({len(gpcs)} GPCs)")
        lines.append("")
        
        # Ordenar por confianza
        gpcs_sorted = sorted(gpcs, key=lambda x: x['classification']['confianza'], reverse=True)
        
        for i, gpc in enumerate(gpcs_sorted, 1):
            title = gpc['title']
            conf = gpc['classification']['confianza']
            ger_url = gpc.get('ger_url', 'N/A')
            grr_url = gpc.get('grr_url', 'N/A')
            
            # Emoji seg√∫n confianza
            if conf >= 80:
                emoji = "‚úÖ"
            elif conf >= 60:
                emoji = "‚ö†Ô∏è"
            else:
                emoji = "‚ùì"
            
            lines.append(f"### {i}. {emoji} {title}")
            lines.append(f"**Confianza:** {conf}%")
            
            if ger_url != 'N/A':
                lines.append(f"- üìÑ **GER:** {ger_url}")
            if grr_url != 'N/A':
                lines.append(f"- üìÑ **GRR:** {grr_url}")
            
            lines.append("")
        
        lines.append("---")
        lines.append("")
    
    # Escribir archivo
    output_file.write_text("\n".join(lines), encoding='utf-8')
    print(f"   ‚úÖ Archivo generado: {output_file}")
    print()

def main():
    print("="*70)
    print("üß¨ CLASIFICACI√ìN SEM√ÅNTICA DE GPCs CON GPU")
    print("="*70)
    print()
    
    # Verificar GPU
    print("üîß Verificando GPU...")
    print(f"   PyTorch version: {torch.__version__}")
    print(f"   CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   GPU device: {torch.cuda.get_device_name(0)}")
        print(f"   GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    print()
    
    # Configurar dispositivo
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üéØ Usando dispositivo: {device}")
    print()
    
    # Cargar GPCs
    print("üìÇ Cargando GPCs...")
    with open(GOD_MODE_FILE, 'r', encoding='utf-8') as f:
        gpcs = json.load(f)
    print(f"   ‚úÖ {len(gpcs)} GPCs cargadas")
    print()
    
    # Cargar modelo de embeddings multiling√ºe
    print("üîÑ Cargando modelo de embeddings...")
    print("   Modelo: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    model = SentenceTransformer(model_name, device=device)
    print(f"   ‚úÖ Modelo cargado en {device}")
    print()
    
    # Crear embeddings de especialidades
    especialidad_embeddings = create_especialidad_embeddings(model)
    
    # Clasificar todas las GPCs
    print(f"üîç Clasificando {len(gpcs)} GPCs...")
    classified_gpcs = []
    
    for gpc in tqdm(gpcs, desc="Clasificando"):
        title = gpc.get('title', 'Sin t√≠tulo')
        classification = classify_gpc_semantic(title, especialidad_embeddings, model)
        
        gpc_classified = gpc.copy()
        gpc_classified['classification'] = classification
        classified_gpcs.append(gpc_classified)
    
    print("\n‚úÖ Clasificaci√≥n completada")
    print()
    
    # Estad√≠sticas
    print("üìä Estad√≠sticas de clasificaci√≥n:")
    by_specialty = {}
    for gpc in classified_gpcs:
        specialty = gpc['classification']['especialidad']
        by_specialty[specialty] = by_specialty.get(specialty, 0) + 1
    
    for specialty, count in sorted(by_specialty.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / len(classified_gpcs)) * 100
        print(f"   {specialty}: {count} GPCs ({percentage:.1f}%)")
    print()
    
    # Generar markdown
    generate_markdown(classified_gpcs, OUTPUT_FILE)
    
    # Guardar JSON con clasificaciones
    json_output = DATA_DIR / "gpc_links_god_mode_classified.json"
    with open(json_output, 'w', encoding='utf-8') as f:
        json.dump(classified_gpcs, f, indent=2, ensure_ascii=False)
    print(f"üíæ JSON guardado: {json_output}")
    print()
    
    print("="*70)
    print("‚úÖ PROCESO COMPLETADO")
    print("="*70)

if __name__ == "__main__":
    main()
